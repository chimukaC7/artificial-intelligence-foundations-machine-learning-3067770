Visualizing and understanding data
Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] 
-When exploring your dataset, you'll need to visualize that data through plotting charts and graphs, so you better understand it. 
-Matplotlib and Seaborn are widely used Python-based 2D plotting libraries. 
-These libraries allow for generating production-quality visualizations with just a few lines of code. 
-Here I've navigated to the Jupiter notebook. Let's start with histograms. 

-Histograms are similar to bar charts and show us the distribution of our numerical data. 
-We'll plot the values for the target variable median house value using a series of bars on the histogram. Here's the histogram. You'll see on the x-axis at the bottom the cost of the home, and on the y-axis on the left the count of homes at that value. We can see from the plot that the values of the median house value are distributed normally with a few outliers here on the right. Most of the homes are within the 100,000 to $200,000 range. Now, let's plot histograms for the remaining features to understand the data distributions. Since ocean proximity is non-numeric, a histogram is not needed. Here we have the histogram for longitude, latitude, housing median age, total rooms, total bedrooms, population, let's scroll down, households, median income, and median house value. Median income is not expressed in US dollars, or USD. The data collection team has pre-processed the data by scaling and capping at 15 for higher median incomes and 0.5 for lower median incomes. Now, these histograms tell us several things. Let's scroll back up to the housing median age. There are several outliers noted here on the right-hand side. Several local peaks are quite gradual; however, this peak here on the right-hand side is really odd at the maximum value, which indicates outliers. The peak becomes more visible by adjusting the bins parameter of the histogram function. Now, let's find median house value down here. Median house value contains outliers, too. There is an odd peak at its maximum value here, around 500,000, which could be an outlier. I'll show you later in the course how to handle outliers so they don't impact the performance of your model. Now let's look at heat maps. Heat maps show the correlation between features or how related one feature is to another feature. If features are highly correlated, that means those features could possibly teach the model the same thing. Duplicate features should be removed to speed up the training process, save money, and improve the model's prediction capabilities. When reading a heat map, expect a line running from top left to bottom right. In each cell, expect values from zero to one. Values closer to zero show a low correlation while values closer to one show a high correlation. We want the heat map to be symmetrical, where the bottom left is the same as the top right, with each feature positively correlated with the other. The heat map shows that several features are correlated. The light pink appears more than once in a row, so consider those two features to be correlated. As expected, the total rooms feature is related to itself, but it is also related to the total bedrooms, population, and households feature. These features are candidates for removal. Dimensionality reduction is the act of removing features to improve the runtime and effectiveness of your models. Now that we understand our dataset, we are ready for feature engineering, a process that manipulates your data by adding, deleting, combining, and creating new features to improve training and prediction capabilities.



Here's a breakdown to help you grasp the concepts better:

Visualization with Matplotlib and Seaborn: These are tools that help you see your data in graphical form. Imagine trying to understand a city's layout from a list of street names versus looking at a map. Matplotlib and Seaborn turn your data “list” into a “map,” making it easier to spot patterns, outliers, and relationships.

Histograms: These are used to show the distribution of a single variable, like the ages of people in a room or, in the video's example, the median house values. A histogram helps you see how values are spread out. For instance, are most houses in the lower price range with a few expensive outliers, or is there a broad spread of prices?

Outliers: These are data points that stand out significantly from the rest. In the context of house prices, an outlier might be a mansion in a neighborhood of modest homes. Identifying outliers is crucial because they can skew your model's learning, leading it to make inaccurate predictions.

Heat Maps: These show the correlation between different variables in your dataset. If you're trying to predict house prices, it's helpful to know which features (like number of bedrooms or proximity to the ocean) are most related to price. A heat map can quickly show you these relationships. High correlation between two features might mean they tell you similar things, and you might not need both.

Feature Engineering: This is the process of creating new features or modifying existing ones to improve your model's performance. It's like refining ingredients in a recipe to enhance the final dish's flavor. The video mentions this as the next step after understanding your data.
